# 최범균님의 카프카 조금 아는 척하기 정리

## 클러스터 기본 구조

![그림1](/assets/img/study/kafka/img.png)

- 카프카 클러스터 
- 브로커 
- 프로듀서 
- 컨수머 
- 주키퍼

### 토픽과 파티션

토픽은 메세지를 구분하는 단위이다. 파일 시스템의 폴더와 유사하다.

파티션은 메세지를 저장하는 물리적인 파일을 의미한다.

프로듀서는 브로커에게 메세지를 보낼때 특정 토픽의 특정 파티션에 저장을 요청한다.

프로듀서가 파티션을 지정하지않으면 라운드로빈으로 파티션에 분배된다.

기본적으로 파티션은 append only file이다.

메세지는 읽어간다고해서 삭제되는것은 아니다.

### 여러 파티션과 컨슈머

![그림1](/assets/img/study/kafka/img_1.png)

컨슈머는 컨슈머 그룹에 속한다.

한개 파티션은 컨슈머 그룹의 한개 컨슈머만 연결이 가능하다. 컨수머 그룹이 다르면 파티션을 공유하는것은 가능하다.

결국에 한 컨슈머그룹 기준으로 파티션의 메세지는 순서대로 처리된다.

### 성능

**페이지 캐시**

- 파일 IO를 디스크가 아닌 메모리 레벨에서 처리하므로 속도가 빠르다.
- 서버에서 페이지 캐시를 카프카만 사용해야 성능에 유리하다.

**Zero Copy**

- 디스크 버퍼에서 네트워크 버퍼로 직접 데이터를 복사한다.

**컨슈머 추적을 위해 브로커가 하는 일이 비교적 단순하다.**

- 메세지 필터, 메세지 재전송과 같은 일은 브로커가 하지 않는다.
    - 프로듀서와 컨슈머가 직접한다.
- 브로커는 컨슈머와 파티션간 매핑을 관리한다.

**배치**

- 묶어서 보내고, 묶어서 받는게 가능하다. 덕분에 네트워크 턴어라운드가 빠르다.

**수평 확장**

- 수평 확장이 쉽다. 브로커를 늘리거나 파티션을 추가하거나 컨수머를 늘리면된다.

### 리플리카

리플리카는 파티션의 복제본을 의미한다. 리플리카의 수 만큼 서로 다른 브로커에 파티션의 복제본이 생긴다.

하나는 리더고 나머지는 팔로워가된다.

# 카프카 프로듀서

![그림1](/assets/img/study/kafka/img_2.png)
batch.size : 배치의 최대 크기
linger.ms : 전송 대기 시간

전송이 성공했는지, 실패했는지 알아야하는경우에는 자바에서는 Future를 받아서 get() 해야한다.

하지만 get() 메소드의 경우 스레드를 블로킹한다. 결국에 하나씩 보내고 결과를 받아야하므로 배치의 효과가 없다.

결과를 꼭 알아야하며, 처리량이 낮아도 되는 경우에만 사용하는게 좋다.

또 다른 방법으로는 send 메소드에 callback 객체를 전달하는 방법이 있다.

이 방법은 블로킹하지않기 때문에 처리량 저하가 없다.

## ack, min.insync.replicas

프로듀서는 전송을 보장하기 위해서 ack 라는 파라미터를 사용한다.
ack = 0 : 서버 응답을 기다리지 않음
ack = 1 : 파티션의 리더에 저장되면 응답 받음, 리더 장애시 메세지 유실 가능
ack = all or -1 : min.insync.replicas 만큼의 리플리카에 저장되면 응답 받음
min.insync.replicas : 최소한으로 충족해야하는 동기화 리플리카 개수

min.insync.replicas를 replica 개수와 동일하게 만들었을 경우 파티션 하나라도 장애가 발생하면 성공 응답을 받을 수 없다.

결국에 리클리카 개수 보다 항상 min.insync.replicas를 작게 만들어야한다.

## 에러 유형

전송 과정에서 실패

- 전송 타임 아웃(일시적인 네트워크 오류 등)
- 리더 다운에 의한 새 리더 선출 진행 중
- 브로커 설정 메세지 크기 한도 초과
- ..

전송 전에 실패

- 직렬화 실패, 프로듀서 자체 요청 크기 제한 초과
- 프로듀서 버퍼가 차서 기다린 시간이 최대 대기 시간 초과
- ..

## 에러 대응

재시도

- 재시도 가능한 에러는 재시도 처리

재시도 위치

- 프로듀서는 자체적으로 브로커 전송 과정에서 에러가 발생하면 재시도 가능한 에러에 대해 재전송을 시도함

재시도를 무한대로 계속하는 경우 다음 메세지 발행이 늦어지므로, 재시도를 무한대로 하면 안된다.

## 재시도와 메세지 중복 전송 가능성

브로커 응답이 늦게 와서 재시도할 경우 중복 발송 가능
![그림1](/assets/img/study/kafka/img_3.png)

## 재시도와 순서

max.in.flight.requests.per.connection

- 블로킹 없이 한 커낵션에서 전송할 수 있는 최대 전송중인 요청 개수
- 이 값이 1보다 크면 재시도 시점에 따라 메세지 순서가 바뀔 수 있음

# 카프카 컨수머

컨수머 그룹 단위로 파티션을 할당한다.

하나의 컨수머가 여러개의 파티션을 컨숨할 수는 있지만, 하나의 파티션이 같은 컨수머 그룹의 여러개의 컨수머에게 컨숨될수는 없다.

컨수머 개수는 파티션보다 많으면 컨수머는 놀게된다.

## 오프셋

컨수머의 poll 메소드는 이전에 커밋한 오프셋이 있으면, 그 이후의 레코드를 읽어온다.

그리고 오프셋의 위치를 읽어온곳으로 수정한다.

![그림1](/assets/img/study/kafka/img_4.png)

auto.offset.reset

- earliest : 맨 처음 오프셋 사용
- latest : 가장 마지막 오프셋 사용

## 컨수머 설정

fetch.min.bytes

- 브로커가 전송할 최소 데이터 크기
- 이 설정값 이상으로 데이터가 쌓일때까지 기다린다.
- 이 값이 크면 대기 시간은 길어지지만, 처리량이 늘어난다.

fetch.max.wait.ms

- 데이터가 최소 크기가 될 때까지 기다릴 시간
- fetch.min.bytes 만큼의 데이터가 쌓이는것을 기다리는 최대 시간

max.partition.fetch.bytes

- 파티션 당 브로커가 리턴할 수 있는 최대 크기

## 자동 커밋

enable.auto.commit 설정

- true : 일정 주기로 컨수머가 읽은 오프셋을 커밋
- false : 수동으로 커밋 실행

auto.commit.interval.ms

- 기본 값 5초

## 수동 커밋
commitSync()
- 커밋에 실패하면 에러 발생

commitAsync()
- 성공 실패 여부를 알려면 콜백을 받아야한다.

## 재처리와 순서
동일 메세지 조회 가능성
- 일시적 커밋 실패, 리밸런스 등에 의해 발생

컨슈머는 멱등성을 고려해야한다.

## 세션 타임아웃, 하트비트, 최대 poll 간격
컨수머는 하트비트를 지속적으로 전송해서 연결을 유지한다.
- 브로커는 컨수머로부터 하트비트가 없으면 컨슈머를 그룹에서 빼고 리밸런스를 진행한다.
- session.timeout.ms: 세션 타임 아웃 시간
- heartbeat.interval.ms: 하트 비트 전송 주기
  - session.timeout.ms의 1/3을 이하를 추천
- max.poll.interval.ms : poll() 메서드의 최대 호출 간격
  - 시간이 지나도록 poll()하지 않으면 컨수머를 그룹에서 빼고 리밸런스 진행

## 종료 처리
다른 스레드에서 wakeup() 메소드 호출
- poll() 메서드가 wakeupException 발생시킨다.

## 컨슈머
카프카 컨수머는 스레드에 안전하지않다. 그래서 wakeup() 메소드를 제외하고, 여러 스레드에서 카프카 컨수머 객체를 동시에 사용하면 안된다.

# 발생할 수 있는 이슈 상황들
1. 데이터 유실 (Data Loss)
 - 문제: Kafka에서 데이터 유실은 주로 브로커 다운, 네트워크 문제, 잘못된 설정 등으로 인해 발생할 수 있습니다. 예를 들어, 프로듀서가 데이터를 전송했지만, 이 데이터가 브로커에 도착하기 전에 문제가 발생하면 데이터가 손실될 수 있습니다.
 - 해결 방법:
   - 복제 팩터(Replication Factor) 설정: 주제(Topic)의 파티션에 복제 팩터를 높게 설정하여, 하나의 브로커가 다운되더라도 다른 브로커에 데이터가 복제되어 있어 데이터 유실을 방지합니다.
   - ACK 설정: 프로듀서의 acks 설정을 all로 설정하여, 모든 복제된 파티션이 데이터를 받은 후에만 프로듀서가 전송 성공을 확인하도록 합니다. 이 설정으로 데이터 유실을 최소화할 수 있습니다.
   - min.insync.replicas 설정: 복제된 파티션 중 최소 몇 개의 파티션이 데이터를 받을 때까지 요청을 받아들이는지 설정하여, 필요한 수준의 데이터 안전성을 확보합니다.

2. 데이터 지연 (Latency)
   - 문제: Kafka에서 데이터 지연은 네트워크 문제, 클러스터 내의 과부하, I/O 병목 등으로 인해 발생할 수 있습니다. 데이터가 제때 처리되지 않으면 실시간 스트리밍의 이점이 사라질 수 있습니다.
   - 해결 방법:
     - 파티션 수 증가: 파티션 수를 늘려 데이터 병렬 처리를 촉진하여 지연을 줄일 수 있습니다. 그러나 파티션 수를 너무 많이 늘리면 오히려 관리 오버헤드가 증가할 수 있으므로 적절한 균형이 필요합니다.
     - 리소스 확장: 브로커, 네트워크 대역폭, 디스크 I/O 등의 리소스를 확장하여 클러스터의 처리 능력을 높입니다.
     - 브로커 설정 최적화: 브로커의 메모리, 네트워크 버퍼 크기, I/O 스레드 수 등을 조정하여 성능을 최적화합니다.

3. 파티션 불균형 (Partition Imbalance)
   - 문제: 특정 파티션에만 데이터가 집중되면, 해당 파티션을 처리하는 브로커에 과부하가 발생하고, 다른 파티션이 덜 사용되면 전체 클러스터의 자원 활용이 비효율적이게 됩니다.
   - 해결 방법:
     - 파티션 키 사용: 데이터를 균등하게 분산시키기 위해 적절한 파티션 키를 사용합니다. 가능하면 데이터가 특정 파티션에 치우치지 않도록 파티션 키를 설계합니다.
     - 리밸런싱(Rebalancing): 클러스터 내 파티션이 불균형하게 분산된 경우, 리밸런싱을 통해 파티션을 재분배합니다. Kafka의 Kafka-reassign-partitions.sh 스크립트를 사용해 파티션을 재분배할 수 있습니다.

4. 오프셋 관리 문제 (Offset Management Issues)
   - 문제: Kafka에서 오프셋은 컨슈머가 읽은 메시지 위치를 나타냅니다. 오프셋 관리가 제대로 이루어지지 않으면 메시지를 중복으로 처리하거나 메시지를 누락할 수 있습니다.
   - 해결 방법:
     - 오프셋 자동 커밋: 오프셋을 주기적으로 자동으로 커밋하도록 설정할 수 있지만, 이 경우 메시지 처리 도중 장애가 발생하면 처리되지 않은 메시지가 누락될 수 있습니다.
     - 오프셋 수동 커밋: 컨슈머 애플리케이션에서 메시지가 안전하게 처리된 후에 오프셋을 수동으로 커밋하도록 설정하여, 데이터 손실이나 중복을 방지합니다.

